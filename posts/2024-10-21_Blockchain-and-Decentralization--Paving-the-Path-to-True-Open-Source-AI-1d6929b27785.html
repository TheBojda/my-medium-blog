<!DOCTYPE html><html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><title>Blockchain and Decentralization: Paving the Path to True Open-Source AI</title><style>
      * {
        font-family: Georgia, Cambria, "Times New Roman", Times, serif;
      }
      html, body {
        margin: 0;
        padding: 0;
      }
      h1 {
        font-size: 50px;
        margin-bottom: 17px;
        color: #333;
      }
      h2 {
        font-size: 24px;
        line-height: 1.6;
        margin: 30px 0 0 0;
        margin-bottom: 18px;
        margin-top: 33px;
        color: #333;
      }
      h3 {
        font-size: 30px;
        margin: 10px 0 20px 0;
        color: #333;
      }
      header {
        width: 640px;
        margin: auto;
      }
      section {
        width: 640px;
        margin: auto;
      }
      section p {
        margin-bottom: 27px;
        font-size: 20px;
        line-height: 1.6;
        color: #333;
      }
      section img {
        max-width: 640px;
      }
      footer {
        padding: 0 20px;
        margin: 50px 0;
        text-align: center;
        font-size: 12px;
      }
      .aspectRatioPlaceholder {
        max-width: auto !important;
        max-height: auto !important;
      }
      .aspectRatioPlaceholder-fill {
        padding-bottom: 0 !important;
      }
      header,
      section[data-field=subtitle],
      section[data-field=description] {
        display: none;
      }
      </style></head><body><article class="h-entry">
<header>
<h1 class="p-name">Blockchain and Decentralization: Paving the Path to True Open-Source AI</h1>
</header>
<section data-field="subtitle" class="p-summary">
The key players in AI can be broadly divided into two camps: advocates of open-source AI and proponents of closed, proprietary AI.
</section>
<section data-field="body" class="e-content">
<section name="2cdc" class="section section--body section--first section--last"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h3 name="c2a4" id="c2a4" class="graf graf--h3 graf--leading graf--title">Blockchain and Decentralization: Paving the Path to True Open-Source AI</h3><figure name="3a9e" id="3a9e" class="graf graf--figure graf-after--h3"><img class="graf-image" data-image-id="1*0jSSdTd7C8Bbog9TcFmpiw.png" data-width="1792" data-height="1024" data-is-featured="true" src="https://cdn-images-1.medium.com/max/800/1*0jSSdTd7C8Bbog9TcFmpiw.png"></figure><p name="1f86" id="1f86" class="graf graf--p graf-after--figure">The key players in AI can be broadly divided into two camps: advocates of open-source AI and proponents of closed, proprietary AI.</p><p name="c669" id="c669" class="graf graf--p graf-after--p">Interestingly, one of the strongest advocates for closed AI is OpenAI, which, despite its name, does not release the source code for its models. Instead, it only offers access to them. Their reasoning is often framed around safety concerns, claiming that releasing these models could pose risks similar to nuclear technology, necessitating centralized control. While this argument has merit, it’s also clear that business interests play a significant role. After all, if ChatGPT’s source code were freely available, who would pay for its services?</p><p name="6ab2" id="6ab2" class="graf graf--p graf-after--p">On the other hand, open-source AI supporters, such as Meta (Facebook), argue that closed AI stifles innovation and that embracing open-source is the way forward. However, business considerations are also at play here. For Meta, AI is not their core product but a tool, so sharing the models doesn’t harm their business. It benefits them, as they can leverage improvements made by the community. Still, there’s a catch — this approach isn’t entirely open-source.</p><p name="88d4" id="88d4" class="graf graf--p graf-after--p">An AI model is a complex mathematical function with adjustable parameters determined during the training process. When a company claims to offer open-source AI, it typically means that these parameters are made publicly available, allowing others to run the model on their systems. However, this doesn’t represent full open-source accessibility.</p><p name="d5e3" id="d5e3" class="graf graf--p graf-after--p">In AI, training is akin to the building process in traditional software development. In this analogy, the model’s parameters are like a compiled binary file. So when companies like Meta, X (formerly Twitter), or others make their models available as open-source, what they’re sharing is just the final product.</p><p name="2898" id="2898" class="graf graf--p graf-after--p">What we receive is a set of parameters for a fixed architecture. If we want to modify or enhance the architecture — for instance, swapping the Transformer architecture with a Mamba architecture — we would need to retrain the model from scratch, which isn’t possible without access to the original training data. As a result, these models can only be fine-tuned, not fundamentally altered or further developed.</p><blockquote name="c986" id="c986" class="graf graf--blockquote graf-after--p"><strong class="markup--strong markup--blockquote-strong">The so-called open-source models are not truly open-source, as the architecture is fixed. These models can only be fine-tuned but not further developed, as that would require the training set as well. True open-source AI consists of both the model and the training set!</strong></blockquote><p name="9dd2" id="9dd2" class="graf graf--p graf--startsWithDoubleQuote graf-after--blockquote">“Open-source” AI models are usually developed by large corporations. This makes sense, as training massive models demands immense computational power and significant financial investment. Only big companies possess the necessary resources, leading to the centralization of AI development.</p><blockquote name="c63b" id="c63b" class="graf graf--blockquote graf-after--p"><strong class="markup--strong markup--blockquote-strong">Just as blockchain technology in the form of Bitcoin created the possibility of decentralized money, it also allows us to create truly open-source AI that is owned by the community instead of a company.</strong></blockquote><p name="4deb" id="4deb" class="graf graf--p graf-after--blockquote">This article presents a concept for developing a truly open-source, community-driven AI by leveraging blockchain technology.</p><p name="69cc" id="69cc" class="graf graf--p graf-after--p">As mentioned earlier, the core of a truly open-source AI lies in having an open dataset, which is the most valuable asset. For example, ChatGPT’s language model was initially trained on publicly available datasets like Common Crawl, then fine-tuned through human oversight (using reinforcement learning with human feedback, or RLHF). This fine-tuning process is particularly costly due to the human labor involved, but it’s what gives ChatGPT its distinctive capabilities. The model architecture itself is likely a general transformer or a variant like the Mixture of Experts, which involves multiple parallel transformers. In essence, the architecture isn’t groundbreaking — what sets models like ChatGPT apart is the quality of the dataset, which drives the model’s performance.</p><p name="e719" id="e719" class="graf graf--p graf-after--p">AI training datasets often span several terabytes, and the content they include varies depending on cultural and group-specific perspectives. The choice of data is crucial, as it can define the “personality” of a large language model. For instance, major scandals have occurred when AI models from companies like Google and Microsoft exhibited racist behavior, largely due to poor dataset selection. Since dataset requirements can differ by culture, creating multiple forks may be necessary. Decentralized, content-addressed storage solutions like IPFS or Ethereum Swarm are ideal for managing these versioned, multi-fork datasets. These systems function similarly to the GIT version control system, where each file is referenced by a hash generated from its content. Forks can be created efficiently in such systems, as only the differences are stored, while the shared portions of the datasets are stored just once.</p><p name="cc48" id="cc48" class="graf graf--p graf-after--p">Once we have the right datasets, we can move forward with training the model.</p><p name="494f" id="494f" class="graf graf--p graf-after--p">As mentioned earlier, an AI model is essentially a large mathematical function with many adjustable parameters. Generally, the more parameters a model has, the more “intelligent” it is, which is why the number of parameters is often included in the model’s name. For instance, llma-2–7b indicates that the model is based on the llma-2 architecture and has 7 billion parameters. During training, these parameters are adjusted using the dataset to ensure the model produces the correct output for a given input. This process is accomplished through backpropagation, which uses partial derivatives to optimize the parameters.</p><p name="c96f" id="c96f" class="graf graf--p graf-after--p">The dataset is divided into batches during training. For each step, a batch provides input and expected output values, and backpropagation is used to adjust the model’s parameters so it can correctly predict the output based on the input. This process is repeated many times until the model reaches the desired level of accuracy, which is verified using a test dataset.</p><p name="8d2d" id="8d2d" class="graf graf--p graf-after--p">Large companies often train models using vast GPU clusters due to the high computational demands of the process. In decentralized systems, however, a key challenge is that individual nodes are unreliable, and this unreliability comes at a cost. This is similar to how Bitcoin’s Proof of Work consensus mechanism consumes massive amounts of energy — trust in the system is achieved by relying on computational power instead of individual node reliability. In contrast, Ethereum’s Proof of Stake mechanism reduces energy consumption by using staked assets to ensure reliability rather than computational power.</p><p name="bd30" id="bd30" class="graf graf--p graf-after--p">In decentralized AI training, there needs to be a way to ensure trust between the training node and the requester. One possible solution is for the training node to log the entire training process, while a third-party validator node performs random checks on the log. If the validator is satisfied with the results, the training node receives payment. The validator does not check the entire log, as that would require duplicating the computations, which would be as resource-intensive as the original training.</p><p name="87b3" id="87b3" class="graf graf--p graf-after--p">Another option is an optimistic approach, where we assume the node performed the computation correctly, but allow a challenge period in which anyone can dispute the result. In this case, the node performing the computation stakes a larger amount (penalty), and the node requesting the computation also stakes an amount (reward). The node performs the computation and then publishes the result. After the node publishes its result, a challenge period (e.g., one day) follows. If an error is found during this time, the challenger receives the penalty, and the requester gets their reward back. If no errors are found, the computing node receives the reward.</p><p name="8a69" id="8a69" class="graf graf--p graf-after--p">There’s also a variant of zero-knowledge proofs, known as zkSNARKs, which can verify computations. The benefit of this method is that verification is inexpensive, but generating the proof is computationally demanding. For AI training, this method is currently too resource-intensive, requiring more computation than the training itself. However, zkML is a growing field of research, and in the future, smart contracts could potentially replace third-party validators by verifying the computation using zkSNARKs.</p><p name="045e" id="045e" class="graf graf--p graf-after--p">From the above, it’s clear there are multiple methods for verifying computations. Based on this, let’s explore how a blockchain-based decentralized training system would be constructed.</p><p name="781d" id="781d" class="graf graf--p graf-after--p">In this system, datasets are collectively owned by the community through DAOs (Decentralized Autonomous Organizations). The DAO determines which data should be included in the dataset. If a subset of members disagrees with these decisions, they can split off to form a new DAO, where they can fork the existing dataset and continue developing it independently. In this way, both the DAO and dataset can be forked. Since the dataset is stored in decentralized, content-addressed storage (like Ethereum Swarm), forking is cost-effective, and the community funds the dataset’s storage.</p><p name="2976" id="2976" class="graf graf--p graf-after--p">The training process is also managed by a DAO. Training nodes that wish to offer their spare computational capacity can register through the DAO. To qualify, each node must stake an amount in a smart contract, which they risk losing if they attempt to cheat during the computation.</p><p name="030a" id="030a" class="graf graf--p graf-after--p">A requester selects the dataset and model they want to train and offers a reward for the task. This offer is public, allowing any training node to apply. The training node then logs the entire training process, with each entry corresponding to the training of a batch. The log includes the input, output, weight matrix, and all relevant parameters (such as the random seed used by the dropout layer). This allows the entire computation to be fully reproduced from the log.</p><p name="0ca6" id="0ca6" class="graf graf--p graf-after--p">As previously mentioned, there are several ways to verify computations. The simplest method is the optimistic approach. In this case, the requester locks the reward in a smart contract, and the training node publishes the training log. A designated period (e.g., one day) is then available for verification. If the requester or anyone else can prove a specific step is incorrect during this time, the training node loses its stake, and the requester retrieves their reward. The person who submits the correct proof earns the stake, incentivizing the community to check the computations. If no proof is submitted, the training node receives the reward when the period ends.</p><p name="5b18" id="5b18" class="graf graf--p graf-after--p">In summary, this is how the system operates, though a few questions remain.</p><h4 name="51a9" id="51a9" class="graf graf--h4 graf-after--p">Who will pay for the cost of training and storing the datasets?</h4><p name="2e81" id="2e81" class="graf graf--p graf-after--h4">The business model of this system mirrors that of many free and open-source solutions, like the Linux model. If a company needs an AI model and is comfortable with it being free and open-source, it’s far more cost-effective to invest in this shared system than to train a proprietary model from scratch. For example, if 10 companies require the same language model and don’t mind it being open, it’s much cheaper for each to cover 1/10th of the training cost rather than for each to bear the full expense individually. The same principle applies to the datasets used for training. Additionally, crowdfunding campaigns could be organized for training models, allowing future users to contribute to their development.</p><h4 name="23af" id="23af" class="graf graf--h4 graf-after--p">Isn’t it cheaper to train models in the cloud?</h4><p name="b79a" id="b79a" class="graf graf--p graf-after--h4">Since prices in such a system are governed by market forces, it’s challenging to provide a definitive answer. The cost will depend on how much unused computational capacity users have available. We’ve already witnessed the power of community-driven systems with Bitcoin, where the network’s computational power exceeds that of any supercomputer. Unlike cloud providers, who need to generate profit, users in a decentralized system can offer their spare computational resources. For example, someone with a high-performance gaming PC can contribute unused capacity when they’re not gaming. If the service generates even slightly more than the energy costs, it becomes worthwhile for the user. Additionally, there is a significant amount of wasted energy worldwide that traditional methods can’t harness. Take thermal energy from volcanoes, for instance — these areas often lack infrastructure for generating electricity. Some startups are already using this energy for Bitcoin mining, so why not apply it to “intelligence mining”? With virtually free energy, the only real cost is the hardware. Therefore, various factors suggest that training models in such a decentralized system could be far cheaper than using cloud services.</p><h4 name="3899" id="3899" class="graf graf--h4 graf-after--p">What about inference?</h4><p name="17e9" id="17e9" class="graf graf--p graf-after--h4">When it comes to running AI models, privacy is a critical concern. While large service providers assure us that our data is handled securely, how can we be certain that no one is listening in on our interactions with models like ChatGPT? Techniques such as homomorphic encryption allow servers to process encrypted data, but they come with significant performance costs. The most secure option is to run models locally. Fortunately, hardware is becoming more powerful, and there are already specialized solutions for running AI models on local devices. The models themselves are also evolving rapidly. Research shows that performance often remains high even after quantization, with minimal degradation, even in extreme cases where weights are represented with as little as 1.5 bits. This is particularly promising because it eliminates multiplication, which is the most resource-intensive operation. As model and hardware advancements continue, we are likely to be able to run models locally that surpass human-level performance. Additionally, with tools like LoRA, we’ll have the ability to customize these models to our personal preferences.</p><div name="7bbf" id="7bbf" class="graf graf--mixtapeEmbed graf-after--p"><a href="https://medium.datadriveninvestor.com/the-enormous-potential-of-binarized-and-1-58-bit-neural-networks-e4209766f6f3" data-href="https://medium.datadriveninvestor.com/the-enormous-potential-of-binarized-and-1-58-bit-neural-networks-e4209766f6f3" class="markup--anchor markup--mixtapeEmbed-anchor" title="https://medium.datadriveninvestor.com/the-enormous-potential-of-binarized-and-1-58-bit-neural-networks-e4209766f6f3"><strong class="markup--strong markup--mixtapeEmbed-strong">The enormous potential of binarized and 1,58-bit neural networks</strong><br><em class="markup--em markup--mixtapeEmbed-em">Quantization is a frequently used method to reduce the memory and computational capacity requirements of our machine…</em>medium.datadriveninvestor.com</a><a href="https://medium.datadriveninvestor.com/the-enormous-potential-of-binarized-and-1-58-bit-neural-networks-e4209766f6f3" class="js-mixtapeImage mixtapeImage u-ignoreBlock" data-media-id="c6e3db6621803513cd78f7ebd56f1bf8" data-thumbnail-img-id="0*nJdX0FrMkdNkhPCJ" style="background-image: url(https://cdn-images-1.medium.com/fit/c/160/160/0*nJdX0FrMkdNkhPCJ);"></a></div><h4 name="a4b6" id="a4b6" class="graf graf--h4 graf-after--mixtapeEmbed">Distributed knowledge</h4><p name="3546" id="3546" class="graf graf--p graf-after--h4">A highly promising approach is retrieval-augmented generation (RAG), where ‘lexical knowledge’ is stored in a vector database, and the language model retrieves the relevant context from this database to answer questions. This mimics how humans process information — no one memorizes an entire dictionary. Instead, when faced with a question, it’s enough to know where to find the necessary information. By reading and interpreting relevant sources, we can formulate coherent answers. This approach offers several advantages. First, it allows the use of a smaller model, which is easier to run locally. Second, it helps reduce hallucination, a common issue in language models. Additionally, expanding the model’s knowledge becomes simple — there’s no need for retraining; you just add new information to the vector database. Ethereum Swarm is well-suited for creating such a database, as it serves not only as decentralized storage but also as a communication platform. For instance, Swarm can facilitate group messaging, allowing the creation of a distributed vector database. A node can publish a search query, and other nodes respond with the relevant knowledge.</p><div name="8afe" id="8afe" class="graf graf--mixtapeEmbed graf-after--p"><a href="https://medium.datadriveninvestor.com/a-concept-of-distributed-artificial-intelligence-aka-a-new-type-of-world-wide-web-48c96da2a528" data-href="https://medium.datadriveninvestor.com/a-concept-of-distributed-artificial-intelligence-aka-a-new-type-of-world-wide-web-48c96da2a528" class="markup--anchor markup--mixtapeEmbed-anchor" title="https://medium.datadriveninvestor.com/a-concept-of-distributed-artificial-intelligence-aka-a-new-type-of-world-wide-web-48c96da2a528"><strong class="markup--strong markup--mixtapeEmbed-strong">A Concept of Distributed Artificial Intelligence aka a New Type of World Wide Web</strong><br><em class="markup--em markup--mixtapeEmbed-em">Do you know how large corporate document databases work, where you can ask questions about the content of millions of…</em>medium.datadriveninvestor.com</a><a href="https://medium.datadriveninvestor.com/a-concept-of-distributed-artificial-intelligence-aka-a-new-type-of-world-wide-web-48c96da2a528" class="js-mixtapeImage mixtapeImage u-ignoreBlock" data-media-id="7db687f7e7cbf9be8d98163dcc08215b" data-thumbnail-img-id="0*tTrOhqahg-46LSIN" style="background-image: url(https://cdn-images-1.medium.com/fit/c/160/160/0*tTrOhqahg-46LSIN);"></a></div><h4 name="6126" id="6126" class="graf graf--h4 graf-after--mixtapeEmbed">Summary: Implementation of LLM OS over Ethereum and Swarm</h4><p name="f752" id="f752" class="graf graf--p graf-after--h4">The concept of LLM OS was first introduced by Andrej Karpathy on Twitter. It envisions a hypothetical operating system built around a large language model. In the context of our blockchain-based distributed system, this can be thought of as an agent running on a user’s node. This agent can communicate with other agents as well as traditional Software 1.0 tools, such as a calculator, Python interpreter, or even control devices like robots, cars, or smart home systems. In our setup, the file system is represented by Ethereum Swarm, along with a vector database built on top of Swarm, where shared knowledge is stored. The entire system, made up of these agents, can be seen as a form of collective intelligence.</p><figure name="9707" id="9707" class="graf graf--figure graf--iframe graf-after--p"></figure><p name="4ab6" id="4ab6" class="graf graf--p graf-after--figure graf--trailing">I believe that in the future, artificial intelligence will be deeply integrated into our daily lives, far beyond what we experience today. AI will essentially become a part of who we are. Instead of relying on mobile phones, we’ll wear smart glasses equipped with cameras that record everything and microphones that capture every sound. We’ll engage in continuous dialogues with language models and other agents running locally, which will fine-tune themselves to meet our needs over time. These agents won’t just interact with us — they’ll also communicate with each other, constantly tapping into the collective knowledge generated by the entire community. This system will transform humanity into a form of collective intelligence, which is incredibly powerful. This collective intelligence mustn’t become controlled by a single company or entity. That’s why systems like the ones discussed, or similar alternatives, are so essential!</p></div></div></section>
</section>
<footer><p>By <a href="https://medium.com/@thebojda" class="p-author h-card">Laszlo Fazekas</a> on <a href="https://medium.com/p/1d6929b27785"><time class="dt-published" datetime="2024-10-21T12:02:07.623Z">October 21, 2024</time></a>.</p><p><a href="https://medium.com/@thebojda/blockchain-and-decentralization-paving-the-path-to-true-open-source-ai-1d6929b27785" class="p-canonical">Canonical link</a></p><p>Exported from <a href="https://medium.com">Medium</a> on October 26, 2024.</p></footer></article></body></html>