<!DOCTYPE html><html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><title>How Genetic Algorithms Can Compete with Gradient Descent and Backprop</title><style>
      * {
        font-family: Georgia, Cambria, "Times New Roman", Times, serif;
      }
      html, body {
        margin: 0;
        padding: 0;
      }
      h1 {
        font-size: 50px;
        margin-bottom: 17px;
        color: #333;
      }
      h2 {
        font-size: 24px;
        line-height: 1.6;
        margin: 30px 0 0 0;
        margin-bottom: 18px;
        margin-top: 33px;
        color: #333;
      }
      h3 {
        font-size: 30px;
        margin: 10px 0 20px 0;
        color: #333;
      }
      header {
        width: 640px;
        margin: auto;
      }
      section {
        width: 640px;
        margin: auto;
      }
      section p {
        margin-bottom: 27px;
        font-size: 20px;
        line-height: 1.6;
        color: #333;
      }
      section img {
        max-width: 640px;
      }
      footer {
        padding: 0 20px;
        margin: 50px 0;
        text-align: center;
        font-size: 12px;
      }
      .aspectRatioPlaceholder {
        max-width: auto !important;
        max-height: auto !important;
      }
      .aspectRatioPlaceholder-fill {
        padding-bottom: 0 !important;
      }
      header,
      section[data-field=subtitle],
      section[data-field=description] {
        display: none;
      }
      </style></head><body><article class="h-entry">
<header>
<h1 class="p-name">How Genetic Algorithms Can Compete with Gradient Descent and Backprop</h1>
</header>
<section data-field="subtitle" class="p-summary">
Although the standard way of training neural networks is gradient descent and backpropagation, some other players are in the game. One of…
</section>
<section data-field="body" class="e-content">
<section name="4244" class="section section--body section--first"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h3 name="289d" id="289d" class="graf graf--h3 graf--leading graf--title">How Genetic Algorithms Can Compete with Gradient Descent and Backprop</h3><figure name="1277" id="1277" class="graf graf--figure graf-after--h3"><img class="graf-image" data-image-id="1*mudAgBfBxHH5IoEd6c3rLA.png" data-width="925" data-height="782" data-is-featured="true" src="https://cdn-images-1.medium.com/max/800/1*mudAgBfBxHH5IoEd6c3rLA.png"><figcaption class="imageCaption">Source: <a href="https://pygad.readthedocs.io/en/latest/" data-href="https://pygad.readthedocs.io/en/latest/" class="markup--anchor markup--figure-anchor" rel="nofollow noopener" target="_blank">https://pygad.readthedocs.io/en/latest/</a></figcaption></figure><p name="0b0b" id="0b0b" class="graf graf--p graf-after--figure">Although the standard way of training neural networks is gradient descent and backpropagation, some other players are in the game. One of them is evolutionary algorithms, such as genetic algorithms.</p><h3 name="92f5" id="92f5" class="graf graf--h3 graf-after--p">Intro to Evolutionary Algorithms</h3><p name="5181" id="5181" class="graf graf--p graf-after--h3">Evolutionary algorithms are mimicking biological evolution. When you are using a genetic algorithm, you need DNA that describes an instance and a fitness function that shows how close a given solution is to achieving the set aims.</p><p name="a466" id="a466" class="graf graf--p graf-after--p">In the first step, a population is created from various random DNAs and the algorithm calculates the fitness values of the instances. In the next step, the algorithm drops a given percent of the population based on the fitness function (weak instances die) and creates new instances by genetic operators. Typical genetic operators are mutation (where the algorithm randomly changes some of the genes) and crossover (where the algorithm randomly exchanges gene sequences in the instances).</p><p name="4054" id="4054" class="graf graf--p graf-after--p">After the application of the operators, the algorithm calculates the new fitness values and repeats the previous steps. In the long term, the average fitness is increasing, and after a sufficient number of iterations, the algorithm finds the solution.</p><p name="0643" id="0643" class="graf graf--p graf-after--p">As you see, the evolutionary searching is mostly random and totally blind compared to the gradient descent which follows the gradient, but it has some good features. One of them is that these algorithms can also be used for non-differentiable functions. If you can describe your solutions with DNA and you can define a fitness function, then you can use them. Another good feature is that these algorithms don’t get stuck in the local minimums and they can run massively parallel because the evaluation of the fitness of the solutions is completely independent.</p><p name="b810" id="b810" class="graf graf--p graf-after--p">Uber AI Lab <a href="https://eng.uber.com/deep-neuroevolution/?ref=hackernoon.com" data-href="https://eng.uber.com/deep-neuroevolution/?ref=hackernoon.com" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">has an article about neuroevolution</a> where they show it is a competitive alternative of training neural networks for reinforcement learning. So, I think it worth knowing about this technology because this can be a better alternative to finding a solution in some cases.</p><h3 name="7582" id="7582" class="graf graf--h3 graf-after--p">Using a Genetic Algorithm to Train a Simple Neural Network to solve the <a href="https://gym.openai.com/envs/CartPole-v1/?ref=hackernoon.com" data-href="https://gym.openai.com/envs/CartPole-v1/?ref=hackernoon.com" class="markup--anchor markup--h3-anchor" rel="noopener" target="_blank">OpenAI CartPole</a> Game</h3><p name="32e7" id="32e7" class="graf graf--p graf-after--h3">That’s enough of the theory, let’s see the code. In this article, we will train a simple neural network to solve the <a href="https://gym.openai.com/envs/CartPole-v1/?ref=hackernoon.com" data-href="https://gym.openai.com/envs/CartPole-v1/?ref=hackernoon.com" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">OpenAI CartPole</a> game. I will use <a href="https://pytorch.org/?ref=hackernoon.com" data-href="https://pytorch.org/?ref=hackernoon.com" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">PyTorch</a> and <a href="https://pygad.readthedocs.io/en/latest/?ref=hackernoon.com" data-href="https://pygad.readthedocs.io/en/latest/?ref=hackernoon.com" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">PyGAD</a>.</p><p name="3833" id="3833" class="graf graf--p graf-after--p">First of all, we define the neural network in PyTorch:</p><pre name="e62f" id="e62f" class="graf graf--pre graf-after--p"><code class="markup--code markup--pre-code">torch.set_grad_enabled(False) <br>model = nn.Sequential( <br>  nn.Linear(observation_space_size, 16), <br>  nn.ReLU(), <br>  nn.Linear(16, 16), <br>  nn.ReLU(), <br>  nn.Linear(16, action_space_size) <br>)</code></pre><p name="83ed" id="83ed" class="graf graf--p graf-after--pre">As you see, it’s a very simple network with 3 linear layers and ReLU. In the first row, we disable gradient calculation, because we don’t need gradients.</p><p name="042c" id="042c" class="graf graf--p graf-after--p">I’m using PyGAD for running the genetic algorithm. PyGAD is a simple, easy-to-use python library for genetic algorithms. It has an extension for PyTorch to create the DNA from the network and build the network from the DNA. In the case of neural networks, the DNA is simply the list of the weights. This network has 386 parameters, so the DNA is a list of 386 numbers. We are generating an initial population with random DNAs which contains 10 initial solutions with the following code:</p><pre name="baf1" id="baf1" class="graf graf--pre graf-after--p"><code class="markup--code markup--pre-code">torch_ga = pygad.torchga.TorchGA(model=model, num_solutions=10)</code></pre><p name="9ae0" id="9ae0" class="graf graf--p graf-after--pre">The most important part of the program is the fitness function. The fitness function evaluates the solution. The input of the function is the DNA, and the return value can be any number.</p><p name="023a" id="023a" class="graf graf--p graf-after--p">The only rule is that the better solution has to be a higher fitness value. In our case, the fitness function will play a game with the neural network which is defined by the DNA and will give back the sum of the rewards. The following code doing this:</p><pre name="6839" id="6839" class="graf graf--pre graf-after--p"><code class="markup--code markup--pre-code">def fitness_func(solution, sol_idx):<br>    global model, observation_space_size, env<br><br>    model_weights_dict = pygad.torchga.model_weights_as_dict(model=model, weights_vector=solution)<br>    model.load_state_dict(model_weights_dict)<br><br>    # play game<br>    observation = env.reset()<br>    sum_reward = 0<br>    done = False<br>    while (not done) and (sum_reward &lt; 1000):<br>        # env.render()<br>        ob_tensor = torch.tensor(observation.copy(), dtype=torch.float)<br>        q_values = model(ob_tensor)<br>        action = np.argmax(q_values).numpy()<br>        observation_next, reward, done, info = env.step(action)<br>        observation = observation_next<br>        sum_reward += reward<br><br>    return sum_reward</code></pre><p name="9df6" id="9df6" class="graf graf--p graf-after--pre">We are using torchga.model_weights_as_dict to get back the weights from the DNA and simply play a game with OpenAI Gym.</p><p name="7c05" id="7c05" class="graf graf--p graf-after--p">When we train the network, one of the biggest bottlenecks is playing the game. It takes the most time. In this case, the algorithm plays 10 games one after another in every round. But why do we have that many processor cores if we don’t use them?</p><p name="5da3" id="5da3" class="graf graf--p graf-after--p">Fortunately, Python has multiprocessing.Pool library to run the game on multiple CPU cores. With multiprocessing.Pool we can define a pool of processes to give various tasks to them. The pool has a map method that gets a function and a list parameter. It distributes the elements of the list among the processes, that run the given function on it. This method just right for us to run the games on multiple cores using the neural network instances of the current population.</p><p name="e634" id="e634" class="graf graf--p graf-after--p">PyGAD has a cal_pop_fitness method which calculates the fitness values for the current population. The current implementation is a simple iteration. We have to override this method and replace the iteration with the map method of the pool:</p><pre name="b98f" id="b98f" class="graf graf--pre graf-after--p"><code class="markup--code markup--pre-code">class PooledGA(pygad.GA):<br><br>    def cal_pop_fitness(self):<br>        global pool<br><br>        pop_fitness = pool.map(fitness_wrapper, self.population)<br>        print(pop_fitness)<br>        pop_fitness = np.array(pop_fitness)<br>        return pop_fitness</code></pre><p name="a436" id="a436" class="graf graf--p graf-after--pre">The complete code looks like this:</p><figure name="b0d1" id="b0d1" class="graf graf--figure graf--iframe graf-after--p"><script src="https://gist.github.com/TheBojda/5f02f03a6c2aa28dcbd60a22b1d4ce7d.js"></script></figure><h3 name="524d" id="524d" class="graf graf--h3 graf-after--figure">Final Thoughts on Genetic Algorithms</h3><p name="1301" id="1301" class="graf graf--p graf-after--h3">Every run takes a different time because of the randomness but on my i7 notebook, the average time to find a good (200+ sum reward) solution is 10 sec. I think it’s not bad.</p><p name="26d4" id="26d4" class="graf graf--p graf-after--p">Gradient descent is a very efficient way to find solutions but in some cases, evolutionary algorithms and other gradient-free algorithms have comparable or better performance thanks to some good features of these techniques.</p><p name="dae4" id="dae4" class="graf graf--p graf-after--p graf--trailing">Create your free account to unlock your custom reading experience.</p></div></div></section><section name="b21f" class="section section--body section--last"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><p name="4235" id="4235" class="graf graf--p graf--leading graf--trailing"><em class="markup--em markup--p-em">Originally published at </em><a href="https://hackernoon.com/how-genetic-algorithms-can-compete-with-gradient-descent-and-backprop-9m9t33bq" data-href="https://hackernoon.com/how-genetic-algorithms-can-compete-with-gradient-descent-and-backprop-9m9t33bq" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank"><em class="markup--em markup--p-em">https://hackernoon.com</em></a><em class="markup--em markup--p-em"> on March 4, 2021.</em></p></div></div></section>
</section>
<footer><p>By <a href="https://medium.com/@thebojda" class="p-author h-card">Laszlo Fazekas</a> on <a href="https://medium.com/p/30b59d5b1ac0"><time class="dt-published" datetime="2021-03-04T00:00:00.000Z">March 4, 2021</time></a>.</p><p><a href="https://medium.com/@thebojda/how-genetic-algorithms-can-compete-with-gradient-descent-and-backprop-30b59d5b1ac0" class="p-canonical">Canonical link</a></p><p>Exported from <a href="https://medium.com">Medium</a> on September 9, 2021.</p></footer></article></body></html>