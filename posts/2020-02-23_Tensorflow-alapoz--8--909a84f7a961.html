<!DOCTYPE html><html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><title>Tensorflow alapozó 8.</title><style>
      * {
        font-family: Georgia, Cambria, "Times New Roman", Times, serif;
      }
      html, body {
        margin: 0;
        padding: 0;
      }
      h1 {
        font-size: 50px;
        margin-bottom: 17px;
        color: #333;
      }
      h2 {
        font-size: 24px;
        line-height: 1.6;
        margin: 30px 0 0 0;
        margin-bottom: 18px;
        margin-top: 33px;
        color: #333;
      }
      h3 {
        font-size: 30px;
        margin: 10px 0 20px 0;
        color: #333;
      }
      header {
        width: 640px;
        margin: auto;
      }
      section {
        width: 640px;
        margin: auto;
      }
      section p {
        margin-bottom: 27px;
        font-size: 20px;
        line-height: 1.6;
        color: #333;
      }
      section img {
        max-width: 640px;
      }
      footer {
        padding: 0 20px;
        margin: 50px 0;
        text-align: center;
        font-size: 12px;
      }
      .aspectRatioPlaceholder {
        max-width: auto !important;
        max-height: auto !important;
      }
      .aspectRatioPlaceholder-fill {
        padding-bottom: 0 !important;
      }
      header,
      section[data-field=subtitle],
      section[data-field=description] {
        display: none;
      }
      </style></head><body><article class="h-entry">
<header>
<h1 class="p-name">Tensorflow alapozó 8.</h1>
</header>
<section data-field="subtitle" class="p-summary">
avagy modellek futtatása mobilon, IoT eszközökön és akár mikrokontrollereken
</section>
<section data-field="body" class="e-content">
<section name="c58e" class="section section--body section--first section--last"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h3 name="eb41" id="eb41" class="graf graf--h3 graf--leading graf--title">Tensorflow alapozó 8.</h3><h4 name="a3f0" id="a3f0" class="graf graf--h4 graf-after--h3 graf--subtitle">modellek futtatása mobilon, IoT eszközökön és akár mikrokontrollereken</h4><figure name="22d4" id="22d4" class="graf graf--figure graf-after--h4"><div class="aspectRatioPlaceholder is-locked" style="max-width: 700px; max-height: 394px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 56.3%;"></div><img class="graf-image" data-image-id="1*Ry0sAkDB6QJEH3KS-KN5dQ.png" data-width="960" data-height="540" data-is-featured="true" src="https://cdn-images-1.medium.com/max/800/1*Ry0sAkDB6QJEH3KS-KN5dQ.png"></div><figcaption class="imageCaption">Forrás: <a href="https://www.cleanpng.com/png-logo-product-design-brand-font-tensorflow-lite-6362296" data-href="https://www.cleanpng.com/png-logo-product-design-brand-font-tensorflow-lite-6362296" class="markup--anchor markup--figure-anchor" rel="noopener" target="_blank">https://www.cleanpng.com/png-logo-product-design-brand-font-tensorflow-lite-6362296</a></figcaption></figure><p name="e682" id="e682" class="graf graf--p graf-after--figure">A Tensorflow egyik nagy előnye, hogy szinte bármilyen eszközre létezik implementációja. Ha betanítunk egy modellt, azt később futtathatjuk mobilon, beágyazott eszközökön, és akár olyan extrém kis erőforrásokkal rendelkező eszközökön is mint amilyenek a mikrokontrollerek. Ebben a cikkben megpróbálom kicsit körbejárni a területet, hogy az olvasónak fogalma legyen arról, hogy mik a lehetőségei. Felülről lefelé fogok haladni, a legnagyobb számítási kapacitással rendelkező mobiltelefonoktól egészen a pár kilóbájt memóriával rendelkező mikróvezérlőkig.</p><p name="78f3" id="78f3" class="graf graf--p graf-after--p">Ha valaki Tensorflow modelleket szeretne futtatni mobilon, az több lehetőség közül is választhat. Ha a fejlesztéshez <a href="https://medium.com/@thebojda/react-native-alapoz%C3%B3-f63dd346382a" data-href="https://medium.com/@thebojda/react-native-alapoz%C3%B3-f63dd346382a" class="markup--anchor markup--p-anchor" target="_blank">React Native-ot</a> használunk, akkor használhatjuk a <a href="https://medium.com/@thebojda/tensorflow-alapoz%C3%B3-7-57eb9a077adc" data-href="https://medium.com/@thebojda/tensorflow-alapoz%C3%B3-7-57eb9a077adc" class="markup--anchor markup--p-anchor" target="_blank">Tensorflow.js</a> <a href="https://github.com/tensorflow/tfjs/tree/master/tfjs-react-native" data-href="https://github.com/tensorflow/tfjs/tree/master/tfjs-react-native" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">React-ra optimalizált változatát</a>. Ebben az esetben a modellt a React Native JavaScript motorja futtatja, ami az expo-gl WebGL kompatibilis OpenGL interfészének köszönhetően képes kihasználni a mobileszközben lévő GPU-t, így teljesítményben valószínűleg nem marad el az alternatívák mögött. Mivel az API teljesen megegyezik a böngészős változattal, aminek egy <a href="https://medium.com/@thebojda/tensorflow-alapoz%C3%B3-7-57eb9a077adc" data-href="https://medium.com/@thebojda/tensorflow-alapoz%C3%B3-7-57eb9a077adc" class="markup--anchor markup--p-anchor" target="_blank">teljes cikket szenteltem</a>, ezért erről nem is írnék sokkal bővebben.</p><p name="e6d0" id="e6d0" class="graf graf--p graf-after--p">A Tensorflow-nak van egy kistestvére, a <a href="https://www.tensorflow.org/lite/guide/get_started" data-href="https://www.tensorflow.org/lite/guide/get_started" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Tensorflow Lite</a>, ami csak a modellek futtatását teszi lehetővé (egyelőre), de a kevés erőforrással rendelkező eszközök igényeit sokkal inkább figyelembe véve, sokkal hatékonyabban. Ahhoz, hogy a Tensorflow modellünket használhassuk TFLite-ban, először át kell konvertálnunk azt a TFLite optimalizált, platformfüggetlen formátumára. Ezt a <a href="https://www.tensorflow.org/lite/convert" data-href="https://www.tensorflow.org/lite/convert" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Tensorflow Lite converter</a> parancssoros interfészével tehetjük meg legkönnyebben.</p><pre name="fa21" id="fa21" class="graf graf--pre graf-after--p">tflite_convert --keras_model_file my_model.h5 --output_file my_model.tflite</pre><p name="367d" id="367d" class="graf graf--p graf-after--pre">A bemenet a szokásos h5 modell, a kimenet pedig a modell tflite-ra konvertált változata. A tflite converter a modell konvertálásán túl képes további optimalizációkat is végrehajtani, így igény esetén csökkenthető a méret, optimalizálhatjuk a modellt fixpontos végrehajtó egységre (pl. edge TPU), stb. Ha kész a tflite modellünk, jöhet a futtatás.</p><p name="bec0" id="bec0" class="graf graf--p graf-after--p">Mobilok esetén React-os Tensorflow változat mellett létezik natív Tensorflow Lite implementáció <a href="https://www.tensorflow.org/lite/guide/android" data-href="https://www.tensorflow.org/lite/guide/android" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Androidra</a> és <a href="https://www.tensorflow.org/lite/guide/ios" data-href="https://www.tensorflow.org/lite/guide/ios" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">iOS</a>-re. Mivel natív iOS fejlesztésben nincs tapasztalatom, ezért most csak az Android megvalósításról beszélnék bővebben. Ha valaki szeretné kipróbálni a dolgot működés közben, az húzza le a <a href="https://github.com/tensorflow/examples" data-href="https://github.com/tensorflow/examples" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Tensorflow Examples repository-t</a>, majd nyissa meg a <a href="https://github.com/tensorflow/examples/tree/master/lite/examples/digit_classifier" data-href="https://github.com/tensorflow/examples/tree/master/lite/examples/digit_classifier" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">digit classifier</a> projekt android részét Android Studio-ban. Ez egy egyszerű kis mobil app, ami egy MINST dataset alapján tanított neurális hálót használ arra, hogy felismerje a felfirkált számjegyeket. A projekt fordítás közben húzza le a tflite modellt, amit aztán megtalálhatunk az asset mappában (a modellt generáló Jupyter notebook <a href="https://github.com/tensorflow/examples/tree/master/lite/examples/digit_classifier/ml" data-href="https://github.com/tensorflow/examples/tree/master/lite/examples/digit_classifier/ml" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">megtalálható a repoban</a>).</p><figure name="a047" id="a047" class="graf graf--figure graf--iframe graf-after--p"></figure><p name="5b40" id="5b40" class="graf graf--p graf-after--figure">A fenti DigitClassifier osztály a program lelke. Itt jön létre a Tensorflow Lite Interpreter ami a konstruktorában megkapja a TFLite modellt, amit a run metódussal futtathatunk.</p><p name="7f3a" id="7f3a" class="graf graf--p graf-after--p">Az Interpretert az 50. sorban hozzuk létre az initializeInterpreter metódusban az asset-ből beolvasott modellből. Ezt követően elkérjük a bemeneti tenzor méretét, hogy később ilyen formára tudjuk konvertálni a bemeneti képet.</p><p name="6dcd" id="6dcd" class="graf graf--p graf-after--p">A classify metódus végzi a tényleges karakterfelismerést. Ennek bemenete egy Bitmap, amit a bemeneti tenzornak megfelelő formába hozunk a createScaledBitmap és a convertBitmapToByteBuffer metódusokkal. Ez utóbbi 0–1 tartományra konvertálja a bemeneti kép pixeleit és a kimenetként egy ByteBuffert ad. Ezzel hívjuk meg az Interpreter run metódusát, ami a második paraméterben megadott result tömbbe fogja rakni az eredményt. Az eredmény a szokásos módon egy 10 elemű tömb, ami azt tartalmazza, hogy a hálózat szerint melyik osztályba mennyire tartozik bele a felismert karakter. Innen választjuk ki a legnagyobb értéket.</p><p name="3870" id="3870" class="graf graf--p graf-after--p">Igazából ennyi az egész. Létrehozzuk az Interpretert, betöltjük a modellt, megfelelő formára hozzuk a bemenetet, lefuttatjuk az interpreter run metódusát, majd értelmezzük a kimenetet. Nem túl bonyolult.</p><p name="8f6c" id="8f6c" class="graf graf--p graf-after--p">Hasonló logika mentén működik a modellek futtatása beágyazott rendszereken, pl. Raspberry Pi-on is. Aki foglalkozott már Raspberry Pi-al, az tudja, hogy a legkedveltebb programozási nyelv (C++ mellett) itt is a Python, így ha valaki neurális hálót futtatna Raspberry Pi-on, célszerű ezt a Tensorflow Lite Python implementációjával megtenni. A minta repository-ból az <a href="https://github.com/tensorflow/examples/tree/master/lite/examples/object_detection/raspberry_pi" data-href="https://github.com/tensorflow/examples/tree/master/lite/examples/object_detection/raspberry_pi" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">object detection projekt</a> érhető el Raspberry Pi-ra. Itt megtalálható minden szükséges instrukció a keretrendszer telepítéséhez.</p><figure name="672d" id="672d" class="graf graf--figure graf--iframe graf-after--p"></figure><p name="a83c" id="a83c" class="graf graf--p graf-after--figure">A fenti rövid kód azt fogalja össze, hogyan használjuk az Tensorflow Lite Interpretert Python környezetben. A modellt a Java-s interfészhez hasonlóan a konstruktorban adjuk át. Ezután a dolog egy kicsit bonyodalmasabb, ugyanis az allocate_tensor metódussal le kell foglalnunk területet az input és output tenzoroknak, amiket a set_tensor és a get_tensor metódusokkal írhatunk és olvashatunk. A set_tensor metódus a paraméterként megadott változó tartalmát átmásolja a natív területre, míg a get_tensor a natív memóriából másolja vissza az eredményt. A hálózatot az Interpreter invoke metódusával futtathatjuk. Bár kicsit nyakatekertebb mint a Java-s megvalósítás, így is mindössze pár sor futtatni a modellt.</p><p name="5f39" id="5f39" class="graf graf--p graf-after--p">A cikk végére hagytam az egyik legizgalmasabb területet, a neurális hálók mikrokontrollereken történő futtatását. Azért gondolom ezt az egyik legizgalmasabb területnek, mivel a számítástechnika két legtávolabbi területét köti össze: a machine learninget, aminek minden terület közül a legnagyobb a számítási kapacitás igénye, és a mikrovezérlőket, amik minden eszköz közül a legkisebb számítási teljesítménnyel rendelkeznek. Példaként egy <a href="https://en.wikipedia.org/wiki/ESP32" data-href="https://en.wikipedia.org/wiki/ESP32" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">ESP32-es processzor</a> 512KiB RAMmal rendelkezik és 240MHz-es órajelen működik. A Tensorflow Lite segítségével ilyen méretű eszközökön is futtathatóak neurális algoritmusok. És hogy miért akarnánk mikrokontrollereken mesterséges intelligenciát futtatni? A lehetőségek száma szinte végtelen: robot vezérlés, okos drónok, intelligens épületek vezérlése, okos protézisek, stb.</p><p name="99ec" id="99ec" class="graf graf--p graf-after--p">Amennyiben a TFLite modellünket mikrokontrolleren szeretnénk használni, a modellt egy plusz lépésben C++ tömbbé kell lefordítanunk, amit hozzászerkesztünk a programunkhoz. Erre azért van szükség, mert ezeken az eszközökön nem fut operációs rendszer, nincs rajtuk fájlrendszer, így ez a legegyszerűbb módja a modell tárolásának. A modell C++ tömbre való fordításához <a href="https://www.tensorflow.org/lite/microcontrollers/build_convert" data-href="https://www.tensorflow.org/lite/microcontrollers/build_convert" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">itt találunk instrukciókat</a>. Ha pedig kíváncsiak vagyunk rá, hogyan néz ki egy ilyen modell, megnézhetjük a <a href="https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/micro/examples/hello_world" data-href="https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/micro/examples/hello_world" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Hello World</a> mintaprojekt <a href="https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/examples/hello_world/sine_model_data.cc" data-href="https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/examples/hello_world/sine_model_data.cc" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">sine_data.cc</a> fájljában. Ez a projekt egy egyszerű hálózatot tartalmaz, aminek a szinusz függvényt tanítottuk be és ami a Tensorflow Lite használatával ki tudja számolni egy-egy szám szinuszát.</p><figure name="7729" id="7729" class="graf graf--figure graf--iframe graf-after--p"></figure><p name="af18" id="af18" class="graf graf--p graf-after--figure">A projekt lényegi részét kimásoltam a fenti gist-be. A modellt az 49. sorban olvassuk be a beforgatott C++ tömbből, majd a 63. sorban hozzuk hozzá létre az interpretert. A konstruktor paraméterként megkapja a modelt, egy opresolvert és a tensor_arena-t. A tensor_arena az a memóriaterület, amit az interpreter futtatásához allokálunk. Ezzel tud gazdálkodni az interpreter. Minél több ez a memória, annál hatékonyabban futtatható a hálózat, de mivel szűkösek az erőforrások, ezért nem mindig allokálható ideális mennyiségű memória. Az opresolver az operátorok futtatását végzi. A példában AllOpsResolvert használjuk, ami minden operátort tartalmaz, de amennyiben nincs szükség minden operátorra, használhatunk kisebb setet, így memóriát takaríthatunk meg. A kód további részeiben a Python implementációból már ismerős AllocateTensors metódus hívása következik, majd a loop ciklusban beállítjuk a tenzorokat és meghívjuk az interpreter Invoke függvényét.</p><p name="d631" id="d631" class="graf graf--p graf-after--p">Dióhéjban ennyit szerettem volna írni a Tensorflow Lite-ról és a Tensorflow modellek mobil, IoT és kis számítási kapacitású eszközökön való futtatásáról. Úgy gondolom, hogy az itt leírtak elegendőek alapozásnak. Ha valaki szeretné magát mélyebben beleásni a témába, az a fenti linkek, valamint a <a href="https://www.tensorflow.org/lite/guide" data-href="https://www.tensorflow.org/lite/guide" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Tensorflow Lite doksi</a> alapján már megtalálhatja a szükséges információkat.</p><p name="3e65" id="3e65" class="graf graf--p graf-after--p">Ha tetszett az írás, olvasd el az előző részeket is:</p><div name="741c" id="741c" class="graf graf--mixtapeEmbed graf-after--p"><a href="https://medium.com/@thebojda/tensorflow-alapoz%C3%B3-d2d1ee97c9db" data-href="https://medium.com/@thebojda/tensorflow-alapoz%C3%B3-d2d1ee97c9db" class="markup--anchor markup--mixtapeEmbed-anchor" title="https://medium.com/@thebojda/tensorflow-alapoz%C3%B3-d2d1ee97c9db"><strong class="markup--strong markup--mixtapeEmbed-strong">TensorFlow alapozó</strong><br><em class="markup--em markup--mixtapeEmbed-em">(neurális hálózatok, tenzorok és képfelismerés a gyakorlatban)</em>medium.com</a><a href="https://medium.com/@thebojda/tensorflow-alapoz%C3%B3-d2d1ee97c9db" class="js-mixtapeImage mixtapeImage u-ignoreBlock" data-media-id="15660260b8dadb0ef12eafefd0be7499" data-thumbnail-img-id="1*T4ARzySpEQvEnr_9pc78pg.jpeg" style="background-image: url(https://cdn-images-1.medium.com/fit/c/160/160/1*T4ARzySpEQvEnr_9pc78pg.jpeg);"></a></div><div name="6fda" id="6fda" class="graf graf--mixtapeEmbed graf-after--mixtapeEmbed"><a href="https://medium.com/@thebojda/tensorflow-alapoz%C3%B3-2-14720a33aca" data-href="https://medium.com/@thebojda/tensorflow-alapoz%C3%B3-2-14720a33aca" class="markup--anchor markup--mixtapeEmbed-anchor" title="https://medium.com/@thebojda/tensorflow-alapoz%C3%B3-2-14720a33aca"><strong class="markup--strong markup--mixtapeEmbed-strong">Tensorflow alapozó 2.</strong><br><em class="markup--em markup--mixtapeEmbed-em">(backpropagation, avagy hogyan működik a varázslat)</em>medium.com</a><a href="https://medium.com/@thebojda/tensorflow-alapoz%C3%B3-2-14720a33aca" class="js-mixtapeImage mixtapeImage u-ignoreBlock" data-media-id="acf8cadc94685ee340590198b4aca40e" data-thumbnail-img-id="1*YTDwPXrnfbPndXxNw77O-w.png" style="background-image: url(https://cdn-images-1.medium.com/fit/c/160/160/1*YTDwPXrnfbPndXxNw77O-w.png);"></a></div><div name="8e02" id="8e02" class="graf graf--mixtapeEmbed graf-after--mixtapeEmbed"><a href="https://medium.com/@thebojda/tensorflow-alapoz%C3%B3-3-ac3d26071b27" data-href="https://medium.com/@thebojda/tensorflow-alapoz%C3%B3-3-ac3d26071b27" class="markup--anchor markup--mixtapeEmbed-anchor" title="https://medium.com/@thebojda/tensorflow-alapoz%C3%B3-3-ac3d26071b27"><strong class="markup--strong markup--mixtapeEmbed-strong">Tensorflow alapozó 3.</strong><br><em class="markup--em markup--mixtapeEmbed-em">(autoencoderek, word2vec és embedding avagy dimenzió redukció neurális hálókkal)</em>medium.com</a><a href="https://medium.com/@thebojda/tensorflow-alapoz%C3%B3-3-ac3d26071b27" class="js-mixtapeImage mixtapeImage u-ignoreBlock" data-media-id="073a0d7e739a04910bab567864201655" data-thumbnail-img-id="1*JOkfva-B2_D3vJV3AYPOCQ.png" style="background-image: url(https://cdn-images-1.medium.com/fit/c/160/160/1*JOkfva-B2_D3vJV3AYPOCQ.png);"></a></div><div name="1ae3" id="1ae3" class="graf graf--mixtapeEmbed graf-after--mixtapeEmbed"><a href="https://medium.com/@thebojda/tensorflow-alapoz%C3%B3-4-cfeee8b9e34c" data-href="https://medium.com/@thebojda/tensorflow-alapoz%C3%B3-4-cfeee8b9e34c" class="markup--anchor markup--mixtapeEmbed-anchor" title="https://medium.com/@thebojda/tensorflow-alapoz%C3%B3-4-cfeee8b9e34c"><strong class="markup--strong markup--mixtapeEmbed-strong">Tensorflow alapozó 4.</strong><br><em class="markup--em markup--mixtapeEmbed-em">(Reinforcement learning, Deep Q-learning és OpenAI Gym)</em>medium.com</a><a href="https://medium.com/@thebojda/tensorflow-alapoz%C3%B3-4-cfeee8b9e34c" class="js-mixtapeImage mixtapeImage u-ignoreBlock" data-media-id="fcc3c58bb1fa6621af2b7b98eac4efa8" data-thumbnail-img-id="1*fBRNFgr42ZsRwFEke0zoUA.jpeg" style="background-image: url(https://cdn-images-1.medium.com/fit/c/160/160/1*fBRNFgr42ZsRwFEke0zoUA.jpeg);"></a></div><div name="9552" id="9552" class="graf graf--mixtapeEmbed graf-after--mixtapeEmbed"><a href="https://medium.com/@thebojda/tensorflow-alapoz%C3%B3-5-df99bc48e306" data-href="https://medium.com/@thebojda/tensorflow-alapoz%C3%B3-5-df99bc48e306" class="markup--anchor markup--mixtapeEmbed-anchor" title="https://medium.com/@thebojda/tensorflow-alapoz%C3%B3-5-df99bc48e306"><strong class="markup--strong markup--mixtapeEmbed-strong">Tensorflow alapozó 5.</strong><br><em class="markup--em markup--mixtapeEmbed-em">Visszacsatolt hálózatok és LSTM</em>medium.com</a><a href="https://medium.com/@thebojda/tensorflow-alapoz%C3%B3-5-df99bc48e306" class="js-mixtapeImage mixtapeImage u-ignoreBlock" data-media-id="af1095d9c81da080648a19e670d10652" data-thumbnail-img-id="1*IMalbwl6uj3nlqxixZYFvA.jpeg" style="background-image: url(https://cdn-images-1.medium.com/fit/c/160/160/1*IMalbwl6uj3nlqxixZYFvA.jpeg);"></a></div><div name="8c23" id="8c23" class="graf graf--mixtapeEmbed graf-after--mixtapeEmbed"><a href="https://medium.com/@thebojda/tensorflow-alapoz%C3%B3-6-1ba1a32a79d5" data-href="https://medium.com/@thebojda/tensorflow-alapoz%C3%B3-6-1ba1a32a79d5" class="markup--anchor markup--mixtapeEmbed-anchor" title="https://medium.com/@thebojda/tensorflow-alapoz%C3%B3-6-1ba1a32a79d5"><strong class="markup--strong markup--mixtapeEmbed-strong">Tensorflow alapozó 6.</strong><br><em class="markup--em markup--mixtapeEmbed-em">GAN-ok, avagy hogyan generáljunk cicákat neurális hálóval</em>medium.com</a><a href="https://medium.com/@thebojda/tensorflow-alapoz%C3%B3-6-1ba1a32a79d5" class="js-mixtapeImage mixtapeImage u-ignoreBlock" data-media-id="1dc770cd0ae3ee59870ee61ffe8a5b46" data-thumbnail-img-id="1*LqPaOCYKuzRjMis_sKWYwQ.png" style="background-image: url(https://cdn-images-1.medium.com/fit/c/160/160/1*LqPaOCYKuzRjMis_sKWYwQ.png);"></a></div><div name="cf95" id="cf95" class="graf graf--mixtapeEmbed graf-after--mixtapeEmbed graf--trailing"><a href="https://medium.com/@thebojda/tensorflow-alapoz%C3%B3-7-57eb9a077adc" data-href="https://medium.com/@thebojda/tensorflow-alapoz%C3%B3-7-57eb9a077adc" class="markup--anchor markup--mixtapeEmbed-anchor" title="https://medium.com/@thebojda/tensorflow-alapoz%C3%B3-7-57eb9a077adc"><strong class="markup--strong markup--mixtapeEmbed-strong">TensorFlow alapozó 7.</strong><br><em class="markup--em markup--mixtapeEmbed-em">TensorFlow.js, avagy neurális hálók futtatása és tanítása böngészőben és Node.js-en</em>medium.com</a><a href="https://medium.com/@thebojda/tensorflow-alapoz%C3%B3-7-57eb9a077adc" class="js-mixtapeImage mixtapeImage u-ignoreBlock" data-media-id="f7bf0d35ae1b2ec9edb43fe981485668" data-thumbnail-img-id="1*YvKKzsjspxIfzY4Xj2e9pQ.png" style="background-image: url(https://cdn-images-1.medium.com/fit/c/160/160/1*YvKKzsjspxIfzY4Xj2e9pQ.png);"></a></div></div></div></section>
</section>
<footer><p>By <a href="https://medium.com/@thebojda" class="p-author h-card">Laszlo Fazekas</a> on <a href="https://medium.com/p/909a84f7a961"><time class="dt-published" datetime="2020-02-23T15:39:17.359Z">February 23, 2020</time></a>.</p><p><a href="https://medium.com/@thebojda/tensorflow-alapoz%C3%B3-8-909a84f7a961" class="p-canonical">Canonical link</a></p><p>Exported from <a href="https://medium.com">Medium</a> on February 23, 2020.</p></footer></article></body></html>