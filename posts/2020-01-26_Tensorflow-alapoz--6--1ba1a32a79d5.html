<!DOCTYPE html><html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><title>Tensorflow alapozó 6.</title><style>
      * {
        font-family: Georgia, Cambria, "Times New Roman", Times, serif;
      }
      html, body {
        margin: 0;
        padding: 0;
      }
      h1 {
        font-size: 50px;
        margin-bottom: 17px;
        color: #333;
      }
      h2 {
        font-size: 24px;
        line-height: 1.6;
        margin: 30px 0 0 0;
        margin-bottom: 18px;
        margin-top: 33px;
        color: #333;
      }
      h3 {
        font-size: 30px;
        margin: 10px 0 20px 0;
        color: #333;
      }
      header {
        width: 640px;
        margin: auto;
      }
      section {
        width: 640px;
        margin: auto;
      }
      section p {
        margin-bottom: 27px;
        font-size: 20px;
        line-height: 1.6;
        color: #333;
      }
      section img {
        max-width: 640px;
      }
      footer {
        padding: 0 20px;
        margin: 50px 0;
        text-align: center;
        font-size: 12px;
      }
      .aspectRatioPlaceholder {
        max-width: auto !important;
        max-height: auto !important;
      }
      .aspectRatioPlaceholder-fill {
        padding-bottom: 0 !important;
      }
      header,
      section[data-field=subtitle],
      section[data-field=description] {
        display: none;
      }
      </style></head><body><article class="h-entry">
<header>
<h1 class="p-name">Tensorflow alapozó 6.</h1>
</header>
<section data-field="subtitle" class="p-summary">
GAN-ok, avagy hogyan generáljunk cicákat neurális hálóval
</section>
<section data-field="body" class="e-content">
<section name="85ba" class="section section--body section--first section--last"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h3 name="d4c6" id="d4c6" class="graf graf--h3 graf--leading graf--title">Tensorflow alapozó 6.</h3><h4 name="e929" id="e929" class="graf graf--h4 graf-after--h3 graf--subtitle">GAN-ok, avagy hogyan generáljunk cicákat neurális hálóval</h4><p name="f993" id="f993" class="graf graf--p graf-after--h4">A generatív hálózatok egy igen izgalmas területe a machine learningnek. Ezek azok a neurális hálók, amik tájképeket, festményeket, vagy éppen emberi arcokat képesek létrehozni.</p><figure name="261b" id="261b" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*fuBNzls3_YTRDPCL9IxZTA.jpeg" data-width="1024" data-height="1024" src="https://cdn-images-1.medium.com/max/800/1*fuBNzls3_YTRDPCL9IxZTA.jpeg"><figcaption class="imageCaption">Forrás: <a href="https://en.wikipedia.org/wiki/Generative_adversarial_network" data-href="https://en.wikipedia.org/wiki/Generative_adversarial_network" class="markup--anchor markup--figure-anchor" rel="noopener" target="_blank">https://en.wikipedia.org/wiki/Generative_adversarial_network</a></figcaption></figure><p name="f7b3" id="f7b3" class="graf graf--p graf-after--figure">A fenti képen látható lánnyal például biztos nem fogunk összefutni az utcán, hiszen őt is egy neurális háló generálta. A generatív hálózatok egyik legnépszerűbb formája a Generative Adversarial Network, vagy röviden GAN. Az architektúra lényege, hogy két neurális hálózatot versenyeztetünk egymással. Az egyik hálózat a generátor, ami egy feature vectorból generál képet. Emlékezzünk kicsit vissza az <a href="https://medium.com/@thebojda/tensorflow-alapoz%C3%B3-3-ac3d26071b27" data-href="https://medium.com/@thebojda/tensorflow-alapoz%C3%B3-3-ac3d26071b27" class="markup--anchor markup--p-anchor" target="_blank">autoencoderes részre</a>. Itt ugye az volt a cél, hogy valamiből (szavakból, képekből, stb.) egy vektor leképzést készítsünk. Ezt úgy értük el, hogy egy encoderrel elóállítottuk a feature vectort, majd egy decoderrel vissza, és ha a visszaállított forma megfelelő volt, a decodert egyszerűen eldobtuk. Így maradt egy hálózatunk, ami képes volt a feature vector előállítására. Nos, a generátor tulajdonképpen az egésznek a decoder része, ami a feature vectorból képes képeket készíteni. Véletlenszerű új képeket pedig úgy generálhatunk, hogy véletlenszerűen generált feature vectorokkal etetjük a generátort. A kérdés már csak az, hogy hogyan készíthetünk ilyen generátort? Itt jön a képbe a másik hálózat, aki a kritikus (discriminator). A kritikus egyetlen célj, hogy az adott képről megmondja, hogy valódi, vagy generált. Úgy is szokták ezt magarázni, hogy az egyik hálózat a “képhamisító”, míg a másik a szakértő. A szakértő célja, hogy kiszúrja a hamisítványokat, míg a hamisító célja, hogy átverje a szekértőt. Ők tehát azok, akik egymással versenyeznek. A tanítás maga úgy történik, hogy a szakértőnek mutatunk pár valódi képet (pl. arcokat), majd pár olyan képet amit a generator készített véletlenszerű feature vectorokból. A minták meg vannak cimkézve valódi/hamis címkékkel, így a hagyományos módon elvégezhető a tanítás. Ezt követően a generatort tanítjuk be véletlenszerű feature vectorokkal, hogy olyan képeket generáljon, amire a szakértő azt mondja, hogy valódi. A tantást követően fejlődik a generator, amivel a szakértőt tanítjuk, így ő is fejlődik, amivel tovább fejlődik a generator, stb.</p><figure name="9a43" id="9a43" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*LqPaOCYKuzRjMis_sKWYwQ.png" data-width="979" data-height="632" data-is-featured="true" src="https://cdn-images-1.medium.com/max/800/1*LqPaOCYKuzRjMis_sKWYwQ.png"><figcaption class="imageCaption">Forrás: <a href="https://www.tensorflow.org/tutorials/generative/dcgan" data-href="https://www.tensorflow.org/tutorials/generative/dcgan" class="markup--anchor markup--figure-anchor" rel="noopener" target="_blank">https://www.tensorflow.org/tutorials/generative/dcgan</a></figcaption></figure><p name="6749" id="6749" class="graf graf--p graf-after--figure">Így versenyez egymással a két hálózat, és így születik meg a folyamat végén a tökéletes generator, ami aztán szinte hibátlan festményeket, cicákat, vagy éppen emberi arcokat generál pusztán véletlen zajból. Ennyi elég is az elméletből, lássuk a kódot! Mivel cicákat generálni elég számításigényes, ezért kézzel írott számjegyeket fogunk generálni.</p><figure name="dd89" id="dd89" class="graf graf--figure graf--iframe graf-after--p"><script src="https://gist.github.com/TheBojda/a7aaaec640e67576bcd0e82a7a6412b3.js"></script><figcaption class="imageCaption">Forrás: <a href="https://gist.github.com/TheBojda/a7aaaec640e67576bcd0e82a7a6412b3" data-href="https://gist.github.com/TheBojda/a7aaaec640e67576bcd0e82a7a6412b3" class="markup--anchor markup--figure-anchor" rel="noopener" target="_blank">https://gist.github.com/TheBojda/a7aaaec640e67576bcd0e82a7a6412b3</a></figcaption></figure><p name="7b60" id="7b60" class="graf graf--p graf-after--figure">Aki ki is próbálná, az <a href="https://colab.research.google.com/gist/TheBojda/77756dfb74f42600bffe214e1d1f8c75/minst_gan_batch_train.ipynb" data-href="https://colab.research.google.com/gist/TheBojda/77756dfb74f42600bffe214e1d1f8c75/minst_gan_batch_train.ipynb" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">itt elérheti Colab notebook formában</a>. Ha futtatjuk a kódot, mindenképp érdemes GPU-ra váltani a Runtime Type-ot a gyors futtatás érdekében.</p><p name="8bcb" id="8bcb" class="graf graf--p graf-after--p">A kód elején betöltjük a <a href="https://en.wikipedia.org/wiki/MNIST_database" data-href="https://en.wikipedia.org/wiki/MNIST_database" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">MINST adathalmazt</a>, ami 60 000 felcimkézett, kézzel írt számjegyet tartalmaz. Mivel nekünk most csak a képek fognak kelleni, a cimkéket eldobjuk. A MINST adathalmaz 28x28-as szürkeárnyalatos képeket tartalmaz, így az elemek 28x28x1-es tenzorok. A pixelek árnyalata 0–255-ig terjedhet. Ezt képezzük le a [-1,1] tartományra.</p><pre name="4968" id="4968" class="graf graf--pre graf-after--p">Model: “sequential”<br>_________________________________________________________________<br>Layer (type) Output Shape Param # <br>=================================================================<br>conv2d (Conv2D) (None, 14, 14, 64) 1664 <br>_________________________________________________________________<br>leaky_re_lu (LeakyReLU) (None, 14, 14, 64) 0 <br>_________________________________________________________________<br>dropout (Dropout) (None, 14, 14, 64) 0 <br>_________________________________________________________________<br>conv2d_1 (Conv2D) (None, 7, 7, 128) 204928 <br>_________________________________________________________________<br>leaky_re_lu_1 (LeakyReLU) (None, 7, 7, 128) 0 <br>_________________________________________________________________<br>dropout_1 (Dropout) (None, 7, 7, 128) 0 <br>_________________________________________________________________<br>flatten (Flatten) (None, 6272) 0 <br>_________________________________________________________________<br>dense (Dense) (None, 1) 6273 <br>=================================================================<br>Total params: 212,865<br>Trainable params: 212,865<br>Non-trainable params: 0<br>_________________________________________________________________</pre><p name="b29e" id="b29e" class="graf graf--p graf-after--pre">A neurális hálók közül a kritikus (discriminator) az egyszerűbb. Ez egy konvolúciós háló. Hasonló, mint amit az <a href="https://medium.com/@thebojda/tensorflow-alapoz%C3%B3-d2d1ee97c9db" data-href="https://medium.com/@thebojda/tensorflow-alapoz%C3%B3-d2d1ee97c9db" class="markup--anchor markup--p-anchor" target="_blank">első részben építettünk</a> a CIFAR-10-es képek felismerésére, csak itt 10 helyett egyetlen kiment van, ami 0–1-ig terjedő skálán mutatja a bemeneti kép valódiságát. Ami még újdonság, az a MaxPool réteg helyett használt LeakyReLu és a Dropout réteg. A <a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/LeakyReLU" data-href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/LeakyReLU" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">LeakyReLu</a> abban különbözik a sima ReLu kimeneti függvénytől, hogy a 0-nál kisebb értékek esetén 0 helyett a bemenet alpha szorosát adja vissza (ami alap esetben 0.3). Ezért is hívják “szivárgó” (leaky) ReLu-nak, mert a 0-nál kisebb értékeket nem vágja le, valamennyire ezek is átszivárognak a kimeneti függvényen. A <a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dropout" data-href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dropout" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Dropout</a> a belementek bizonyos százalékát véletlenszerűen eldobja (0-ra állítja). Ezt a réteget azért szokták használni, hogy a hálózat ne tanulja meg teljesen pontosan a mintákat (<a href="https://en.wikipedia.org/wiki/Overfitting" data-href="https://en.wikipedia.org/wiki/Overfitting" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">overfitting</a>), ehelyett próbálja kinyerni a lényeges komponenseket. A hálózat végén a szokásos Flatten és egy teljesen csatolt Dense réteg található.</p><pre name="6bc5" id="6bc5" class="graf graf--pre graf-after--p">Model: “sequential_1”<br>_________________________________________________________________<br>Layer (type) Output Shape Param # <br>=================================================================<br>dense_1 (Dense) (None, 12544) 1254400 <br>_________________________________________________________________<br>batch_normalization (BatchNo (None, 12544) 50176 <br>_________________________________________________________________<br>leaky_re_lu_2 (LeakyReLU) (None, 12544) 0 <br>_________________________________________________________________<br>reshape (Reshape) (None, 7, 7, 256) 0 <br>_________________________________________________________________<br>conv2d_transpose (Conv2DTran (None, 7, 7, 128) 819200 <br>_________________________________________________________________<br>batch_normalization_1 (Batch (None, 7, 7, 128) 512 <br>_________________________________________________________________<br>leaky_re_lu_3 (LeakyReLU) (None, 7, 7, 128) 0 <br>_________________________________________________________________<br>conv2d_transpose_1 (Conv2DTr (None, 14, 14, 64) 204800 <br>_________________________________________________________________<br>batch_normalization_2 (Batch (None, 14, 14, 64) 256 <br>_________________________________________________________________<br>leaky_re_lu_4 (LeakyReLU) (None, 14, 14, 64) 0 <br>_________________________________________________________________<br>conv2d_transpose_2 (Conv2DTr (None, 28, 28, 1) 1600 <br>=================================================================<br>Total params: 2,330,944<br>Trainable params: 2,305,472<br>Non-trainable params: 25,472<br>_________________________________________________________________</pre><p name="9eb1" id="9eb1" class="graf graf--p graf-after--pre">A generátor tulajdonképpen egy fordított konvolúciós háló. Az első réteg egy 12544 neuronból álló teljesen csatolt Dense réteg. Mivel egy 100 elemű véletlenszerű feature vectorból indulunk ki, ezért minden neuronnak 100 bemenete lesz. Ebben a rétegben áll elő az a 12544 érték, amit a <a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/Reshape" data-href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/Reshape" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Reshape</a> réteg 7x7x256-os tenzorrá konvertál és amit a hálózat 28x28x1-es kimeneti tenzorrá fog felskálázni. Ehhez a <a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2DTranspose" data-href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2DTranspose" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Conv2DTranspose</a> réteget használja, ami tulajdonképpen egy fordított konvolúció. Míg a konvolúció egy tenzort kisebb tenzorra képez le a fontos jellemzők kinyerésével, addig a Conv2DTranspose a jellemzők tenzorából generál egy nagyobb tenzort.</p><pre name="1bd7" id="1bd7" class="graf graf--pre graf-after--p">discriminator.trainable = False<br>gan = models.Sequential([<br>    generator,<br>    discriminator<br>])</pre><p name="799f" id="799f" class="graf graf--p graf-after--pre">Van egy harmadik hálózatunk is gan néven, aminek első rétege a generator, a második a discriminator. Erre a hálózatra a tanításhoz van szükség. A hálózat létrehozása előtt a discriminator trainable tulajdonságát False-ra állítjuk. Ettől a discriminator maga még tanítható, de mikor a gan-t tanítjuk, a rendszer konstansnak veszi, és csak a generator súlyait változtatja. A generatort tehát nem közvetlenül, hanem a gan-on keresztül tanítjuk. A gan bemenete a 100 elemű zajvektor, a kimenete pedig egy 0–1-ig terjedő szám, ami azt mondja meg, hogy mennyire valós a generator által előállított kép. Az elvárt kimenet tehát mindig 1 lesz a tanításnál, mivel azt szeretnénk, hogy igazinak tűnjenek a képek. Hogy tisztább legyen, lássuk hogy megy a tanítás:</p><pre name="972a" id="972a" class="graf graf--pre graf-after--p">noise = tf.random.normal([BATCH_SIZE, noise_dim])<br>fake_images = generator.predict(noise)<br><br>real_images_y = np.ones((BATCH_SIZE, 1))<br>discriminator.train_on_batch(images, real_images_y)<br><br>fake_images_y = np.zeros((BATCH_SIZE, 1))<br>discriminator.train_on_batch(fake_images, fake_images_y)<br><br>gan_y = np.ones((BATCH_SIZE, 1))<br>gan.train_on_batch(noise, gan_y)</pre><p name="6542" id="6542" class="graf graf--p graf-after--pre">Minden lépésben (epoch) generálunk egy BATCH_SIZE méretű zajtenzort, aminek minden eleme egy 100 elemű véletlenszerű feature vector. Ezt nyomjuk keresztül a generatoron, hogy létrejöjjenek a hamis képek. Első körben a discriminatort tanítjuk a valós képekkel. Ezek esetén az elvárt kimenet 1-es (valódi). A következő körben még mindig a discriminatort tanítjuk, csak ezesetben az elvárt kimenet 0 (hamis). Most hogy a discriminatorunk eggyel jobban tud igazi és hamis képeket megkülönböztetni, jöhet a generator tanítása a gan hálózaton keresztül. Ennek bemenete ugyancsak a zajtenzor, az elvárt kimenet pedig 1-es (valódi). Mivel a tanítás a discriminatorra nincs hatással, ezért a generator súlyait fogja úgy módosítani a rendszer, hogy az eredmény minél közelebb legyen az 1-hez. Ha a folyamatot kellően sokszor ismételjük, a generator végül megtanul egészen valósághű képeket generálni.</p><figure name="f128" id="f128" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*2soOkaTgh3-3tq5SzKwziA.gif" data-width="288" data-height="288" src="https://cdn-images-1.medium.com/max/800/1*2soOkaTgh3-3tq5SzKwziA.gif"><figcaption class="imageCaption">Forrás: <a href="https://www.tensorflow.org/tutorials/generative/dcgan" data-href="https://www.tensorflow.org/tutorials/generative/dcgan" class="markup--anchor markup--figure-anchor" rel="noopener" target="_blank">https://www.tensorflow.org/tutorials/generative/dcgan</a></figcaption></figure><p name="4ae6" id="4ae6" class="graf graf--p graf-after--figure">A fenti animált GIF-en jól látszik, hogyan lesznek a kezdeti véletlen zajból végül kézzel írt számok a tanítási fázisok alatt.</p><p name="d9f4" id="d9f4" class="graf graf--p graf-after--p">Ha valaki kipróbálja a kódot Colabban GPU-val, az tapasztalhatja, hogy egy epoch kb. 20 másodpercig tart, ami nem kevés. Az erdeti Tensorflow tutorialban található kód esetén ez az érték 10 másodperc. Ez a 2x-es gyorsulás az egyedi tanításnak kösznhető. Úgy gondoltam, hogy a GAN működését jobban meg lehet érteni a fenti train_on_bach függvényt használó kód alapján, ezért használtam ezt a megoldást, ugyanakkor mindenképp érdemes vetni egy pillantást az eredeti megoldásra (<a href="https://colab.research.google.com/gist/TheBojda/d82bc67f17239d6a057cc91b1956601a/minst_gan.ipynb" data-href="https://colab.research.google.com/gist/TheBojda/d82bc67f17239d6a057cc91b1956601a/minst_gan.ipynb" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">ez is elérhető Colabban</a>).</p><figure name="56e9" id="56e9" class="graf graf--figure graf--iframe graf-after--p"><script src="https://gist.github.com/TheBojda/9e67906ec478c8c005fb23f768a5e48b.js"></script><figcaption class="imageCaption">Forrás: <a href="https://gist.github.com/TheBojda/9e67906ec478c8c005fb23f768a5e48b" data-href="https://gist.github.com/TheBojda/9e67906ec478c8c005fb23f768a5e48b" class="markup--anchor markup--figure-anchor" rel="noopener" target="_blank">https://gist.github.com/TheBojda/9e67906ec478c8c005fb23f768a5e48b</a></figcaption></figure><p name="710f" id="710f" class="graf graf--p graf-after--figure">Az egyik lényeges pont, hogy ennél a megoldásnál saját hibafüggvényeket definiálunk.</p><pre name="07cf" id="07cf" class="graf graf--pre graf-after--p">def discriminator_loss(real_output, fake_output):<br>    real_loss = cross_entropy(tf.ones_like(real_output), real_output)<br>    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)<br>    total_loss = real_loss + fake_loss<br>    return total_loss<br><br><br>def generator_loss(fake_output):<br>    return cross_entropy(tf.ones_like(fake_output), fake_output)</pre><p name="74ad" id="74ad" class="graf graf--p graf-after--pre">A discriminator_loss függvény visszatérési értéke a discriminator valódi és hamis képekre adott hibájának az összege, míg a generator esetén a hamis képekre adott hibát számoljuk. Mindkét esetben a <a href="https://www.tensorflow.org/api_docs/python/tf/keras/losses/BinaryCrossentropy" data-href="https://www.tensorflow.org/api_docs/python/tf/keras/losses/BinaryCrossentropy" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">BinaryCrossentropy</a> hibafüggvényt használjuk, amit az <a href="https://medium.com/@thebojda/tensorflow-alapoz%C3%B3-d2d1ee97c9db" data-href="https://medium.com/@thebojda/tensorflow-alapoz%C3%B3-d2d1ee97c9db" class="markup--anchor markup--p-anchor" target="_blank">első részből</a> már ismerhetünk.</p><pre name="fd92" id="fd92" class="graf graf--pre graf-after--p">@tf.function<br>def train_step(images):<br>    noise = tf.random.normal([BATCH_SIZE, noise_dim])<br><br>    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:<br>        generated_images = generator(noise, training=True)<br><br>        real_output = discriminator(images, training=True)<br>        fake_output = discriminator(generated_images, training=True)<br><br>        gen_loss = generator_loss(fake_output)<br>        disc_loss = discriminator_loss(real_output, fake_output)<br><br>    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)<br>    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)<br><br>    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))<br>    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))</pre><p name="6923" id="6923" class="graf graf--p graf-after--pre">Maga a tanítás egy csomó érdekes megoldást alkalmaz. Ott van például a GradientTape, amiről a <a href="https://medium.com/@thebojda/tensorflow-alapoz%C3%B3-2-14720a33aca" data-href="https://medium.com/@thebojda/tensorflow-alapoz%C3%B3-2-14720a33aca" class="markup--anchor markup--p-anchor" target="_blank">második részben</a> volt szó. Ő az, aki a hálózat futtatása közben összeszedi a gradienseket, ami alapján módosíthatjuk a súlyokat. A fenti példában rögtön kettő GradientTape-et is indítunk. Az egyiktől a generatorra vonatkozó gradienseket szedjük össze, a másiktó a discriminatorra. A gradiensek segítségével optimalizáljuk a hálózatokat. Az optimalizáláshoz a jól megszokott Adam-et használjuk. Maga az előre futtatás (forward phase) annyiból áll, hogy a zajtenzor alapján legeneráljuk a hamis képeket. Ezekre lefuttatjuk a discriminatort, majd kiszámoljuk a hibákat.</p><p name="6b78" id="6b78" class="graf graf--p graf-after--p">Ami még érdekesség, az a <a href="https://www.tensorflow.org/api_docs/python/tf/function" data-href="https://www.tensorflow.org/api_docs/python/tf/function" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">tf.function</a> decorator. Pythonban a <a href="https://www.geeksforgeeks.org/decorators-in-python/" data-href="https://www.geeksforgeeks.org/decorators-in-python/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">decorator</a> afféle csomagoló függvény. Ha egy függvényt ilyennel látunk el, akkor mikor használjuk, valójában nem a függvényt hívjuk, hanem egy másik függvényt, amit a decorator visszaadott. A tf.function azt csinálja, hogy a dekorált függvényt tensorflow gráffá fordítja. Maga a gráf a natív rétegben jön létre, így mikor meghívjuk a függvényt, a paraméterek közvetlenül a natív réteghez kerülnek, ami végigfuttatja azokat. A tf.function tehát sokkal gyorsabb futtatást tesz lehetővé.</p><p name="3527" id="3527" class="graf graf--p graf-after--p">Ezzel a két megoldással, tehát a tf.function és a GradientTape használatával érhető el a fent említett 2x-es gyorsulás.</p><p name="8a24" id="8a24" class="graf graf--p graf-after--p">Körülbelül ennyit szerettem volna írni a GAN-okról. Aki esetleg hiányolja a címben említett cicákat, az <a href="https://github.com/simoninithomas/CatDCGAN" data-href="https://github.com/simoninithomas/CatDCGAN" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">itt találhat egy kódot</a> cicák generálására. A fejlesztő szerint a képen látható cicák 20 órányi tanításba és 170$-ba kerültek neki. Erre gondoltam, mikor azt írtam, hogy cicákat generálni számításigényes feladat.</p><p name="c062" id="c062" class="graf graf--p graf-after--p">A GAN-oknak nagyon sok továbbfejlesztett változata létezik. A <a href="https://www.thispersondoesnotexist.com/" data-href="https://www.thispersondoesnotexist.com/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">https://www.thispersondoesnotexist.com/</a> például StyleGAN-t használ, de ugyancsak erre a technológiára épül a <a href="https://affinelayer.com/pixsrv/" data-href="https://affinelayer.com/pixsrv/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Pix2pix</a> amivel béna kis szabadkezi rajzokat alakíthatunk műalkotássá. Ezen kívül használják őket <a href="https://en.wikipedia.org/wiki/Deepfake" data-href="https://en.wikipedia.org/wiki/Deepfake" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">DeepFake</a> videók létrehozásánál, és <a href="https://en.wikipedia.org/wiki/Generative_adversarial_network" data-href="https://en.wikipedia.org/wiki/Generative_adversarial_network" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">még megannyi helyen</a>. Akit mélyebben érdekel a téma, az rengeteg anyagot találhat neten. Remélem ez a kis írás jó alapot biztosít majd a további kutatáshoz.</p><p name="2de4" id="2de4" class="graf graf--p graf-after--p">Ha tetszett az írás, olvasd el a korábbi részeket is:</p><div name="f677" id="f677" class="graf graf--mixtapeEmbed graf-after--p"><a href="https://medium.com/@thebojda/tensorflow-alapoz%C3%B3-d2d1ee97c9db" data-href="https://medium.com/@thebojda/tensorflow-alapoz%C3%B3-d2d1ee97c9db" class="markup--anchor markup--mixtapeEmbed-anchor" title="https://medium.com/@thebojda/tensorflow-alapoz%C3%B3-d2d1ee97c9db"><strong class="markup--strong markup--mixtapeEmbed-strong">TensorFlow alapozó</strong><br><em class="markup--em markup--mixtapeEmbed-em">(neurális hálózatok, tenzorok és képfelismerés a gyakorlatban)</em>medium.com</a><a href="https://medium.com/@thebojda/tensorflow-alapoz%C3%B3-d2d1ee97c9db" class="js-mixtapeImage mixtapeImage u-ignoreBlock" data-media-id="15660260b8dadb0ef12eafefd0be7499" data-thumbnail-img-id="1*T4ARzySpEQvEnr_9pc78pg.jpeg" style="background-image: url(https://cdn-images-1.medium.com/fit/c/160/160/1*T4ARzySpEQvEnr_9pc78pg.jpeg);"></a></div><div name="277d" id="277d" class="graf graf--mixtapeEmbed graf-after--mixtapeEmbed"><a href="https://medium.com/@thebojda/tensorflow-alapoz%C3%B3-2-14720a33aca" data-href="https://medium.com/@thebojda/tensorflow-alapoz%C3%B3-2-14720a33aca" class="markup--anchor markup--mixtapeEmbed-anchor" title="https://medium.com/@thebojda/tensorflow-alapoz%C3%B3-2-14720a33aca"><strong class="markup--strong markup--mixtapeEmbed-strong">Tensorflow alapozó 2.</strong><br><em class="markup--em markup--mixtapeEmbed-em">(backpropagation, avagy hogyan működik a varázslat)</em>medium.com</a><a href="https://medium.com/@thebojda/tensorflow-alapoz%C3%B3-2-14720a33aca" class="js-mixtapeImage mixtapeImage u-ignoreBlock" data-media-id="acf8cadc94685ee340590198b4aca40e" data-thumbnail-img-id="1*YTDwPXrnfbPndXxNw77O-w.png" style="background-image: url(https://cdn-images-1.medium.com/fit/c/160/160/1*YTDwPXrnfbPndXxNw77O-w.png);"></a></div><div name="e2d0" id="e2d0" class="graf graf--mixtapeEmbed graf-after--mixtapeEmbed"><a href="https://medium.com/@thebojda/tensorflow-alapoz%C3%B3-3-ac3d26071b27" data-href="https://medium.com/@thebojda/tensorflow-alapoz%C3%B3-3-ac3d26071b27" class="markup--anchor markup--mixtapeEmbed-anchor" title="https://medium.com/@thebojda/tensorflow-alapoz%C3%B3-3-ac3d26071b27"><strong class="markup--strong markup--mixtapeEmbed-strong">Tensorflow alapozó 3.</strong><br><em class="markup--em markup--mixtapeEmbed-em">(autoencoderek, word2vec és embedding avagy dimenzió redukció neurális hálókkal)</em>medium.com</a><a href="https://medium.com/@thebojda/tensorflow-alapoz%C3%B3-3-ac3d26071b27" class="js-mixtapeImage mixtapeImage u-ignoreBlock" data-media-id="073a0d7e739a04910bab567864201655" data-thumbnail-img-id="1*JOkfva-B2_D3vJV3AYPOCQ.png" style="background-image: url(https://cdn-images-1.medium.com/fit/c/160/160/1*JOkfva-B2_D3vJV3AYPOCQ.png);"></a></div><div name="a226" id="a226" class="graf graf--mixtapeEmbed graf-after--mixtapeEmbed"><a href="https://medium.com/@thebojda/tensorflow-alapoz%C3%B3-4-cfeee8b9e34c" data-href="https://medium.com/@thebojda/tensorflow-alapoz%C3%B3-4-cfeee8b9e34c" class="markup--anchor markup--mixtapeEmbed-anchor" title="https://medium.com/@thebojda/tensorflow-alapoz%C3%B3-4-cfeee8b9e34c"><strong class="markup--strong markup--mixtapeEmbed-strong">Tensorflow alapozó 4.</strong><br><em class="markup--em markup--mixtapeEmbed-em">(Reinforcement learning, Deep Q-learning és OpenAI Gym)</em>medium.com</a><a href="https://medium.com/@thebojda/tensorflow-alapoz%C3%B3-4-cfeee8b9e34c" class="js-mixtapeImage mixtapeImage u-ignoreBlock" data-media-id="fcc3c58bb1fa6621af2b7b98eac4efa8" data-thumbnail-img-id="1*fBRNFgr42ZsRwFEke0zoUA.jpeg" style="background-image: url(https://cdn-images-1.medium.com/fit/c/160/160/1*fBRNFgr42ZsRwFEke0zoUA.jpeg);"></a></div><div name="f40e" id="f40e" class="graf graf--mixtapeEmbed graf-after--mixtapeEmbed"><a href="https://medium.com/@thebojda/tensorflow-alapoz%C3%B3-5-df99bc48e306" data-href="https://medium.com/@thebojda/tensorflow-alapoz%C3%B3-5-df99bc48e306" class="markup--anchor markup--mixtapeEmbed-anchor" title="https://medium.com/@thebojda/tensorflow-alapoz%C3%B3-5-df99bc48e306"><strong class="markup--strong markup--mixtapeEmbed-strong">Tensorflow alapozó 5.</strong><br><em class="markup--em markup--mixtapeEmbed-em">Visszacsatolt hálózatok és LSTM</em>medium.com</a><a href="https://medium.com/@thebojda/tensorflow-alapoz%C3%B3-5-df99bc48e306" class="js-mixtapeImage mixtapeImage u-ignoreBlock" data-media-id="af1095d9c81da080648a19e670d10652" data-thumbnail-img-id="1*IMalbwl6uj3nlqxixZYFvA.jpeg" style="background-image: url(https://cdn-images-1.medium.com/fit/c/160/160/1*IMalbwl6uj3nlqxixZYFvA.jpeg);"></a></div><p name="016d" id="016d" class="graf graf--p graf-after--mixtapeEmbed">A következő részt pedig itt találod:</p><div name="19db" id="19db" class="graf graf--mixtapeEmbed graf-after--p graf--trailing"><a href="https://medium.com/@thebojda/tensorflow-alapoz%C3%B3-7-57eb9a077adc" data-href="https://medium.com/@thebojda/tensorflow-alapoz%C3%B3-7-57eb9a077adc" class="markup--anchor markup--mixtapeEmbed-anchor" title="https://medium.com/@thebojda/tensorflow-alapoz%C3%B3-7-57eb9a077adc"><strong class="markup--strong markup--mixtapeEmbed-strong">TensorFlow alapozó 7.</strong><br><em class="markup--em markup--mixtapeEmbed-em">TensorFlow.js, avagy neurális hálók futtatása és tanítása böngészőben és Node.js-en</em>medium.com</a><a href="https://medium.com/@thebojda/tensorflow-alapoz%C3%B3-7-57eb9a077adc" class="js-mixtapeImage mixtapeImage u-ignoreBlock" data-media-id="f7bf0d35ae1b2ec9edb43fe981485668" data-thumbnail-img-id="1*YvKKzsjspxIfzY4Xj2e9pQ.png" style="background-image: url(https://cdn-images-1.medium.com/fit/c/160/160/1*YvKKzsjspxIfzY4Xj2e9pQ.png);"></a></div></div></div></section>
</section>
<footer><p>By <a href="https://medium.com/@thebojda" class="p-author h-card">Laszlo Fazekas</a> on <a href="https://medium.com/p/1ba1a32a79d5"><time class="dt-published" datetime="2020-01-26T10:26:26.668Z">January 26, 2020</time></a>.</p><p><a href="https://medium.com/@thebojda/tensorflow-alapoz%C3%B3-6-1ba1a32a79d5" class="p-canonical">Canonical link</a></p><p>Exported from <a href="https://medium.com">Medium</a> on March 9, 2021.</p></footer></article></body></html>